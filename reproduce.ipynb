{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Systematic Comparison of Metric Learning Loss Functions for End-to-End Speaker Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the code to reproduce the Equal Error Rate (EER) of the Additive Angular Margin (AAM) loss model from the paper `A Systematic Comparison of Metric Learning Loss Functions for End-to-End Speaker Embedding`.\n",
    "\n",
    "Before you begin, make sure you have installed the `pyannote.db.voxceleb` plugin [here](https://github.com/pyannote/pyannote-db-voxceleb).\n",
    "\n",
    "If you use this model, please cite our paper:\n",
    "\n",
    "```BibTeX Entry```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before beginning, we make sure all the needed libraries are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from xarray import DataArray\n",
    "from pyannote.core.utils.distance import cdist\n",
    "from pyannote.audio.applications.speaker_embedding import SpeakerEmbedding\n",
    "from pyannote.database import get_protocol, FileFinder\n",
    "from pyannote.audio.features.utils import get_audio_duration\n",
    "from pyannote.metrics.binary_classification import det_curve\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also initialize the database with the preprocessors needed, and we define some useful functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessors make sure to look for wav files and to calculate the audio duration\n",
    "preprocessors = {'audio': FileFinder(), 'duration': get_audio_duration}\n",
    "# We use the VoxCeleb1_X protocol, with a train and dev set resulting from splitting de original dev\n",
    "protocol = get_protocol('VoxCeleb.SpeakerVerification.VoxCeleb1_X', preprocessors=preprocessors)\n",
    "\n",
    "\n",
    "# This will later be useful to get embeddings for evaluation and for score normalization\n",
    "def get_embedding(file, pretrained, mean=False):\n",
    "    emb = []\n",
    "    for f in file.files():\n",
    "\n",
    "        if 'try_with' in f:\n",
    "            segments = f['try_with']\n",
    "        else:\n",
    "            segments = f['annotation'].get_timeline()\n",
    "                \n",
    "        for segment in segments:\n",
    "            emb.append(pretrained(f).crop(segment, mode='center'))\n",
    "\n",
    "    emb = np.vstack(emb)\n",
    "    if mean:\n",
    "        emb = np.mean(emb, axis=0, keepdims=True)\n",
    "    return emb\n",
    "\n",
    "\n",
    "# This will calculate the DET curve of the model on a subset of VoxCeleb1_X\n",
    "def run_experiment(distance, subset):\n",
    "\n",
    "    y_pred, y_true = [], []\n",
    "    for trial in tqdm(getattr(protocol, f'{subset}_trial')()):\n",
    "\n",
    "        file1 = trial['file1']\n",
    "        hash1 = get_hash(file1)\n",
    "\n",
    "        file2 = trial['file2']\n",
    "        hash2 = get_hash(file2)\n",
    "\n",
    "        y_pred.append(distance.data[index1[hash1], index2[hash2]])\n",
    "        y_true.append(trial['reference'])\n",
    "    \n",
    "    y_pred = np.array(y_pred)\n",
    "    y_true = np.array(y_true)\n",
    "    \n",
    "    fpr, fnr, thresholds, eer = det_curve(y_true, y_pred, distances=True)\n",
    "    \n",
    "    return {\n",
    "        'eer': eer,\n",
    "        'fpr': fpr,\n",
    "        'fnr': fnr,\n",
    "        'thresholds': thresholds,\n",
    "        'y_true': y_true,\n",
    "        'y_pred': y_pred}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Pre-trained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing to do is to load the model from TorchHub. This is achieved with a single line of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /people/coria/.cache/torch/hub/pyannote_pyannote-audio_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding has dimension 512.\n"
     ]
    }
   ],
   "source": [
    "# Segments of 4 seconds extracted with a sliding window of 100ms\n",
    "# The parameter `step` is a fraction of `duration`\n",
    "# Make sure to change the device to `cpu` if your machine doesn't have a GPU\n",
    "model = torch.hub.load('pyannote/pyannote-audio', 'emb_voxceleb', duration=4, step=0.025, device='cuda')\n",
    "\n",
    "print(f'Embedding has dimension {model.dimension:d}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next sections we will evaluate this model on `VoxCeleb1.test` with and without Adaptive S-Norm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating with Raw Distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the model is downloaded and ready, we can use it for inference. Here we evaluate it only using the cosine distance between embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 37720/37720 [08:34<00:00, 73.37it/s] \n"
     ]
    }
   ],
   "source": [
    "get_hash = lambda file: SpeakerEmbedding.get_hash(file)\n",
    "\n",
    "# hash to embedding mapping\n",
    "cache1 = dict()\n",
    "cache2 = dict()\n",
    "\n",
    "# hash to index mapping\n",
    "index1 = dict()\n",
    "index2 = dict()\n",
    "\n",
    "n_file1 = 0\n",
    "n_file2 = 0\n",
    "\n",
    "# Get embeddings for every trial in the test subset\n",
    "for trial in tqdm(protocol.test_trial(), total=37720):\n",
    "    \n",
    "    file1 = trial['file1']\n",
    "    hash1 = get_hash(file1)\n",
    "    if hash1 not in cache1:\n",
    "        cache1[hash1] = get_embedding(file1, model, mean=True)\n",
    "        index1[hash1] = n_file1\n",
    "        n_file1 += 1\n",
    "    \n",
    "    file2 = trial['file2']\n",
    "    hash2 = get_hash(file2)\n",
    "    if hash2 not in cache2:\n",
    "        cache2[hash2] = get_embedding(file2, model, mean=True)\n",
    "        index2[hash2] = n_file2\n",
    "        n_file2 += 1\n",
    "\n",
    "hashes1 = list(cache1.keys())\n",
    "hashes2 = list(cache2.keys())\n",
    "emb1 = np.vstack(list(cache1.values()))\n",
    "emb2 = np.vstack(list(cache2.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the cosine distance for each trial\n",
    "distance = DataArray(\n",
    "    cdist(emb1, emb2, metric='cosine'),\n",
    "    dims=('file1', 'file2'),\n",
    "    coords=(hashes1, hashes2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "37720it [00:12, 2917.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER with raw distances: 4.12\n"
     ]
    }
   ],
   "source": [
    "# Calculate the DET curve on test and print the EER value\n",
    "raw_results = run_experiment(distance, 'test')\n",
    "print(f\"EER with raw distances: {100 * raw_results['eer']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating with Adaptive S-Norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we improve the above EER with the score normalization method called Adaptive S-Norm, which consists in:\n",
    "\n",
    "1) Determining a cohort set of embeddings (different from the model's training set, in our case `VoxCeleb2.dev`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 109847/143506 [2:00:49<32:48, 17.10it/s]  "
     ]
    }
   ],
   "source": [
    "# Get cohort embeddings from VoxCeleb1_X.train\n",
    "cohort_embedding = dict()\n",
    "for cohort_file in tqdm(protocol.train(), total=143506):\n",
    "    speaker = cohort_file['annotation'].argmax()\n",
    "    embedding = get_embedding(cohort_file, model, mean=False)\n",
    "    cohort_embedding.setdefault(speaker, []).append(embedding)\n",
    "\n",
    "# The cohort consists of the mean embedding for each speaker\n",
    "cohort_speakers = list(cohort_embedding.keys())\n",
    "cohort = np.vstack([np.mean(np.vstack(cohort_embedding[speaker]), axis=0, keepdims=True) \n",
    "                    for speaker in cohort_speakers])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Calculating the raw score of the trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the distances between each trial embedding (file1 and file2) and the cohort\n",
    "distance1 = DataArray(\n",
    "    cdist(emb1, cohort, metric='cosine'),\n",
    "    dims=('file1', 'cohort'),\n",
    "    coords=(hashes1, cohort_speakers))\n",
    "\n",
    "distance2 = DataArray(\n",
    "    cdist(emb2, cohort, metric='cosine'),\n",
    "    dims=('file2', 'cohort'),\n",
    "    coords=(hashes2, cohort_speakers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Calculating the mean and std of N most similar scores to each embedding in the trials (N=500 in our case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is our N\n",
    "COHORT_SIZE = 500\n",
    "\n",
    "# Calculate mean and std of N most similar cohort embeddings for all file1\n",
    "data1 = np.partition(distance1.data, COHORT_SIZE)[:, :COHORT_SIZE]\n",
    "mz = np.mean(data1, axis=1) \n",
    "sz = np.std(data1, axis=1)\n",
    "mz = DataArray(mz, dims=('file1',), coords=(hashes1,))\n",
    "sz = DataArray(sz, dims=('file1',), coords=(hashes1,))\n",
    "\n",
    "# Calculate mean and std of N most similar cohort embeddings for all file2\n",
    "data2 = np.partition(distance2.data, COHORT_SIZE)[:, :COHORT_SIZE]\n",
    "mt = np.mean(data2, axis=1) \n",
    "st = np.std(data2, axis=1)\n",
    "mt = DataArray(mt, dims=('file2',), coords=(hashes2,))\n",
    "st = DataArray(st, dims=('file2',), coords=(hashes2,))\n",
    "\n",
    "# Normalize\n",
    "distance_z = (distance - mz) / sz\n",
    "distance_t = (distance - mt) / st\n",
    "distance_s = 0.5 * (distance_z + distance_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Normalizing the trial's score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the DET curve on test and print the EER value\n",
    "ada_snorm_results = run_experiment(distance_s, 'test')\n",
    "print(f\"EER with Adaptive S-Norm: {100 * ada_snorm_results['eer']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's all! If you have any questions or suggestions, please feel free to open an issue in [pyannote-audio](https://github.com/pyannote/pyannote-audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
